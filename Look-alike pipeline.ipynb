{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libs\n",
    "\n",
    "import os\n",
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import gc\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import getpass\n",
    "import geopandas as gpd\n",
    "\n",
    "set_matplotlib_formats('retina')\n",
    "sns.set_palette('pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up DB connection\n",
    "\n",
    "os.environ['ORACLE_HOME'] = \"oraclepath\"\n",
    "dns_tns = cx_Oracle.makedsn('ip','7777',service_name = 'servicename')\n",
    "usr = getpass.getpass(prompt='Insert username:\\n')\n",
    "pwd = getpass.getpass(prompt='Insert password:\\n')\n",
    "conn = cx_Oracle.connect(user=usr, password=pwd, dsn=dns_tns, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load target group\n",
    "\n",
    "df_taret = pd.read_sql('''''', con=conn, parse_dates = date_columns)\n",
    "#df_taret = pd.read_csv('')\n",
    "df_taret.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load control group (where look-alike is to be found)\n",
    "\n",
    "df_all = pd.read_sql('''''',con=conn, parse_dates = date_columns)\n",
    "#df_all = pd.read_csv('')\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility methods\n",
    "\n",
    "def change_to_date(x):\n",
    "    try:\n",
    "        return pd.to_datetime(x)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def get_standard_regions(df,column):\n",
    "    map_df = gpd.read_file('regions2010_alb_shp/regions2010.shp', encoding='cp1251')\n",
    "    map_df = map_df[map_df['geometry'].notnull()]\n",
    "\n",
    "    prefixes = {}\n",
    "    for every in map_df['region'].unique():\n",
    "        lower = every.lower()\n",
    "        tokens = lower.split(' ')\n",
    "        for word in tokens:\n",
    "            word = word.replace(\"(\", \"\")\n",
    "            word = word.replace(\")\", \"\")\n",
    "            if word[:5] not in ['респу', 'облас', 'округ', 'автон', 'ао', 'город', 'край', '+']:\n",
    "                prefixes[word[:5]] = every\n",
    "    prefixes['башк'] = 'Республика Башкирия'\n",
    "    \n",
    "    df[column] = df[column].apply(lambda x: x.lower() if pd.notnull(x) else None)\n",
    "    \n",
    "    for prefix, full_name in prefixes.items():\n",
    "        df.at[df[column].str.contains(prefix, na=False), column] = full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_standard_regions(df_target, 'REGION')\n",
    "get_standard_regions(df_all, 'REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['TARGET']=0\n",
    "df_target['TARGET']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize class balance\n",
    "\n",
    "final_df = pd.concat([df_all.sample(df_target.shape[0]),df_target],ignore_index=True)\n",
    "final_df['TARGET'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns with almost identical values\n",
    "\n",
    "for column in final_df.columns:\n",
    "    if final_df[column].value_counts(normalize=True).iloc[0]>0.99:\n",
    "        final_df=final_df.drop(column,1)\n",
    "        print(str(column)+' deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns with more than 30% NaN\n",
    "\n",
    "for column in final_df.columns:\n",
    "    if final_df[column].notnull().value_counts(normalize=True).loc[True]<0.70:\n",
    "        final_df=final_df.drop(column,1)\n",
    "        print(str(column)+' deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder\n",
    "te_region = TargetEncoder()\n",
    "final_df['REGION'] = te_region.fit_transform(final_df['REGION'],final_df['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_woe_iv(dataset, feature, target):\n",
    "    lst = []\n",
    "    for i in range(dataset[feature].nunique()):\n",
    "        val = list(dataset[feature].unique())[i]\n",
    "        lst.append({\n",
    "            'Value': val,\n",
    "            'All': dataset[dataset[feature] == val].count()[feature],\n",
    "            'Good': dataset[(dataset[feature] == val) & (dataset[target] == 0)].count()[feature],\n",
    "            'Bad': dataset[(dataset[feature] == val) & (dataset[target] == 1)].count()[feature]\n",
    "        })\n",
    "        \n",
    "    dset = pd.DataFrame(lst)\n",
    "    dset['Distr_Good'] = dset['Good'] / dset['Good'].sum()\n",
    "    dset['Distr_Bad'] = dset['Bad'] / dset['Bad'].sum()\n",
    "    dset['WoE'] = np.log(dset['Distr_Good'] / dset['Distr_Bad'])\n",
    "    dset = dset.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    dset['IV'] = (dset['Distr_Good'] - dset['Distr_Bad']) * dset['WoE']\n",
    "    iv = dset['IV'].sum()\n",
    "    \n",
    "    dset = dset.sort_values(by='WoE')\n",
    "    \n",
    "    return dset, iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in final_df.dtypes[final_df.dtypes=='object'].index:\n",
    "        df, iv = calculate_woe_iv(final_df, col, 'TARGET')\n",
    "        best_predictors = df[df['IV']>0.02][['Value','IV']]\n",
    "        if not best_predictors.empty:\n",
    "            print(col)\n",
    "            print('Leaving important values: '+ str(best_predictors['Value'].values))\n",
    "            final_df[col]= final_df[col].apply(lambda x: x if x in best_predictors['Value'].values else 'OTHER')\n",
    "        else:\n",
    "            \n",
    "            print('Dropped useless column:'+col)\n",
    "            final_df = final_df.drop(col,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in final_df.dtypes[final_df.dtypes=='object'].index:\n",
    "    print(column)\n",
    "    print(final_df[column].nunique())\n",
    "    final_df = final_df.join(pd.get_dummies(final_df[column],prefix=column+'_'))\n",
    "    final_df = final_df.drop(column,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transliterate import translit, get_available_language_codes\n",
    "for every in final_df.columns:\n",
    "    new_name = str(translit(every,'ru', reversed=True))\n",
    "    final_df[new_name]=final_df[every]\n",
    "    if new_name!=every:\n",
    "        final_df = final_df.drop(every,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "gc.collect()\n",
    "X = final_df.drop('TARGE',1)\n",
    "y = final_df['TARGET']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True, random_state = 42)\n",
    "scores = []\n",
    "f_i = np.zeros(X.shape[1])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    gc.collect()\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    model = lgb.LGBMClassifier(n_jobs=12,random_state = 42, class_weight='balanced')\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores.append(roc_auc_score(y_pred,y_test))\n",
    "    f_i = np.add(f_i,model.feature_importances_)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranking = pd.DataFrame({'Value':f_i,'Feature':X.columns})\n",
    "ranking = ranking.sort_values(by='Value',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "p_fpr, p_tpr, _ = metrics.roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "roc_val = np.mean(scores)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('Receiver Operating Characteristic ALL')\n",
    "plt.plot(p_fpr, p_tpr, linestyle=':', color='red', label = 'ROC AUC score = %0.2f' % roc_val)\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "n_scores = []\n",
    "n_list =[50,30,20,10,5]\n",
    "\n",
    "for best_n in n_list:\n",
    "    \n",
    "    cv_scores=[]\n",
    "    \n",
    "    best_n_names=ranking['Feature'].iloc[:best_n].values.tolist()  \n",
    "    X = final_df.drop('TARGET',1)[best_n_names]\n",
    "    y = final_df['TARGET']\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        gc.collect()\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = lgb.LGBMClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        cv_scores.append(roc_auc_score(y_pred,y_test))\n",
    "        gc.collect() \n",
    "        \n",
    "    n_scores.append(np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(n_list,n_scores)\n",
    "plt.ylim(0.85,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-996fa0a57e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mselected_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mranking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Feature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "selected_df = final_df[ranking.iloc[:100]['Feature'].values]\n",
    "\n",
    "for column in selected_df.columns:\n",
    "    selected_df[column] = selected_df[column].fillna(selected_df[column].median())\n",
    "    \n",
    "selected_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_mat = selected_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in corr_mat:\n",
    "    print(column)\n",
    "    print('Correlated:')\n",
    "    corr_cols=corr_mat[abs(corr_mat[column])>0.4].index.tolist()\n",
    "    print(corr_cols)\n",
    "    if len(corr_cols)>1:\n",
    "        corr_cols.remove(ranking.loc[ranking[ranking['Feature'].isin(corr_cols)]['Value'].idxmax()]['Feature'])\n",
    "        for every in corr_cols :\n",
    "            if every !='TARGET':\n",
    "                try:\n",
    "                    selected_df = selected_df.drop(every,1)\n",
    "                except Exception as e:\n",
    "                        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "sns.heatmap(selected_df.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_mat = selected_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in corr_mat:\n",
    "    print(column)\n",
    "    print('Correlated:')\n",
    "    corr_cols=corr_mat[abs(corr_mat[column])>0.4].index.tolist()\n",
    "    print(corr_cols)\n",
    "    if len(corr_cols)>1:\n",
    "        corr_cols.remove(ranking.loc[ranking[ranking['Feature'].isin(corr_cols)]['Value'].idxmax()]['Feature'])\n",
    "        for every in corr_cols :\n",
    "            if every !='TARGET':\n",
    "                try:\n",
    "                    selected_df = selected_df.drop(every,1)\n",
    "                except Exception as e:\n",
    "                        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "sns.heatmap(selected_df.corr(method='spearman'),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-training on selected features & Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(n_splits=10,shuffle=True,class_weight='balanced')\n",
    "\n",
    "model.fit(selected_df,final_df['TARGET'])\n",
    "y_pred = model.predict_proba(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(selected_df)\n",
    "print(roc_auc_score(y_pred_train,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df['LGBM_SCORE']=y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df_log = selected_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_log.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'CLUSTERS' in final_df_log.columns:\n",
    "    final_df_log = final_df_log.drop('CLUSTERS',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, PowerTransformer\n",
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "#scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df_scaled = scaler.fit_transform(final_df_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понижаем размерность "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(0.95)\n",
    "df_PCA = pca.fit_transform(final_df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(df_PCA[(final_df['TARGET']==1).values,0],df_PCA[(final_df['TARGET']==1).values,1])\n",
    "plt.scatter(df_PCA[(final_df['TARGET']==0).values,0],df_PCA[(final_df['TARGET']==0).values,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "ax.scatter(df_PCA[(final_df['TARGET']==1),0],df_PCA[(final_df['TARGET']==1),1],df_PCA[(final_df['TARGET']==1),2])\n",
    "ax.scatter(df_PCA[(final_df['TARGET']==0),0],df_PCA[(final_df['TARGET']==0),1],df_PCA[(final_df['TARGET']==0),2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import gc\n",
    "\n",
    "inertia = []\n",
    "silhouette = []\n",
    "for k in range(2,25):\n",
    "    gc.collect()\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k,init='k-means++',random_state=22)\n",
    "    kmeans.partial_fit(df_PCA)\n",
    "    inertia.append(np.sqrt(kmeans.inertia_))\n",
    "    silhouette.append(silhouette_score(df_PCA,kmeans.labels_,metric='euclidean',sample_size=100000,random_state=22))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(range(2,25),inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(range(2,25),silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "kmeans = MiniBatchKMeans(n_clusters=22,init='k-means++',random_state=22)\n",
    "y_clusters = kmeans.fit_predict(df_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['CLUSTERS'] = y_clusters\n",
    "target_balance = final_df.groupby('CLUSTERS')[['TARGET']].mean()\n",
    "cluster_balance = final_df[final_df['TARGET']==0]['CLUSTERS'].value_counts(normalize=True)\n",
    "mean_score = final_df[final_df['TARGET']==0].groupby('CLUSTERS')[['LGBM_SCORE']].mean()\n",
    "clustering_report = bio_balance.join(cluster_balance).join(mean_score)\n",
    "clustering_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.barplot(x='CLUSTERS',y='TARGET',data=final_df)\n",
    "\n",
    "avg_level = final_df['TARGET'].value_counts(normalize=True).loc[1]\n",
    "fst = final_df['CLUSTERS'].min()\n",
    "sec = final_df['CLUSTERS'].max()\n",
    "sns.lineplot(x=[fst,sec],y=[avg_level,avg_level])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
